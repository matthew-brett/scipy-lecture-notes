{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d13fc14c",
   "metadata": {},
   "source": [
    "# scikit-learn: machine learning in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d003aed0",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e1d604",
   "metadata": {},
   "source": [
    "**Authors**: *Gael Varoquaux*\n",
    "\n",
    "![](images/scikit-learn-logo.png)\n",
    "\n",
    "**Start of admonition: Prerequisites**\n",
    "\n",
    " * :ref:`numpy <numpy>`\n",
    " * :ref:`scipy <scipy>`\n",
    " * :ref:`matplotlib (optional) <matplotlib>`\n",
    " * :ref:`ipython (the enhancements come handy) <interactive_work>`\n",
    "**End of admonition**\n",
    "\n",
    ":::{sidebar} Acknowledgements\n",
    "\n",
    "This chapter is adapted from [a\n",
    "tutorial](https://www.youtube.com/watch?v=r4bRUvvlaBw) given by Gaël\n",
    "Varoquaux, Jake Vanderplas, Olivier Grisel.\n",
    "\n",
    ":::\n",
    "\n",
    "**Start of admonition: See also**\n",
    "\n",
    "**Data science in Python**\n",
    "\n",
    "- The {ref}`statistics` chapter may also be of interest\n",
    "  for readers looking into machine learning.\n",
    "- The [documentation of scikit-learn](https://scikit-learn.org) is\n",
    "  very complete and didactic.\n",
    "\n",
    "**End of admonition**\n",
    "\n",
    "## Introduction: problem settings\n",
    "\n",
    "### What is machine learning?\n",
    "\n",
    "**Start of note**\n",
    ":class: dropdown\n",
    "\n",
    "Machine Learning is about building programs with **tunable\n",
    "parameters** that are adjusted automatically so as to improve their\n",
    "behavior by **adapting to previously seen data.**\n",
    "\n",
    "Machine Learning can be considered a subfield of **Artificial\n",
    "Intelligence** since those algorithms can be seen as building blocks\n",
    "to make computers learn to behave more intelligently by somehow\n",
    "**generalizing** rather that just storing and retrieving data items\n",
    "like a database system would do.\n",
    "**End of note**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5e7de7",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# we create 50 separable synthetic points\n",
    "X, Y = make_blobs(n_samples=50, centers=2, random_state=0, cluster_std=0.60)\n",
    "\n",
    "# fit the model\n",
    "clf = SGDClassifier(loss=\"hinge\", alpha=0.01, fit_intercept=True)\n",
    "clf.fit(X, Y)\n",
    "\n",
    "# plot the line, the points, and the nearest vectors to the plane\n",
    "xx = np.linspace(-1, 5, 10)\n",
    "yy = np.linspace(-1, 5, 10)\n",
    "X1, X2 = np.meshgrid(xx, yy)\n",
    "Z = np.empty(X1.shape)\n",
    "for (i, j), val in np.ndenumerate(X1):\n",
    "    x1 = val\n",
    "    x2 = X2[i, j]\n",
    "    p = clf.decision_function([[x1, x2]])\n",
    "    Z[i, j] = p[0]\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "ax = plt.axes()\n",
    "ax.contour(\n",
    "    X1, X2, Z, [-1.0, 0.0, 1.0], colors=\"k\", linestyles=[\"dashed\", \"solid\", \"dashed\"]\n",
    ")\n",
    "ax.scatter(X[:, 0], X[:, 1], c=Y, cmap=\"Paired\")\n",
    "ax.set_title('A classification problem')\n",
    "ax.axis(\"tight\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b01acc",
   "metadata": {},
   "source": [
    "We'll take a look at two very simple machine learning tasks here. The\n",
    "first is a **classification** task: the figure shows a collection of\n",
    "two-dimensional data, colored according to two different class labels. A\n",
    "classification algorithm may be used to draw a dividing boundary between\n",
    "the two clusters of points:\n",
    "\n",
    "By drawing this separating line, we have learned a model which can\n",
    "**generalize** to new data: if you were to drop another point onto the\n",
    "plane which is unlabeled, this algorithm could now **predict** whether\n",
    "it's a blue or a red point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468544ac",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# x from 0 to 30\n",
    "rng = np.random.default_rng()\n",
    "x = 30 * rng.random((20, 1))\n",
    "# y = a*x + b with noise\n",
    "y = 0.5 * x + 1.0 + rng.normal(size=x.shape)\n",
    "\n",
    "# create a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(x, y)\n",
    "\n",
    "# predict y from the data\n",
    "x_new = np.linspace(0, 30, 100)\n",
    "y_new = model.predict(x_new[:, np.newaxis])\n",
    "\n",
    "# plot the results\n",
    "plt.figure(figsize=(4, 3))\n",
    "ax = plt.axes()\n",
    "ax.scatter(x, y)\n",
    "ax.plot(x_new, y_new)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.axis(\"tight\")\n",
    "ax.set_title('A regression problem');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5bdc18",
   "metadata": {},
   "source": [
    "The next simple task we'll look at is a **regression** task: a simple\n",
    "best-fit line to a set of data.\n",
    "\n",
    "Again, this is an example of fitting a model to data, but our focus here\n",
    "is that the model can make generalizations about new data. The model has\n",
    "been **learned** from the training data, and can be used to predict the\n",
    "result of test data: here, we might be given an x-value, and the model\n",
    "would allow us to predict the y value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b95021d",
   "metadata": {},
   "source": [
    "### Data in Scikit-learn\n",
    "\n",
    "#### The data matrix\n",
    "\n",
    "Machine learning algorithms implemented in scikit-learn expect data\n",
    "to be stored in a **two-dimensional array or matrix**. The arrays can be\n",
    "either `numpy` arrays, or in some cases `scipy.sparse` matrices. The\n",
    "size of the array is expected to be `[n_samples, n_features]`\n",
    "\n",
    "- **n_samples:** The number of samples: each sample is an item to\n",
    "  process (e.g. classify). A sample can be a document, a picture, a\n",
    "  sound, a video, an astronomical object, a row in database or CSV\n",
    "  file, or whatever you can describe with a fixed set of quantitative\n",
    "  traits.\n",
    "- **n_features:** The number of features or distinct traits that can\n",
    "  be used to describe each item in a quantitative manner. Features are\n",
    "  generally real-valued, but may be boolean or discrete-valued in some\n",
    "  cases.\n",
    "\n",
    "**Start of note**\n",
    ":class: dropdown\n",
    "\n",
    "The number of features must be fixed in advance. However it can be\n",
    "very high dimensional (e.g. millions of features) with most of them\n",
    "being zeros for a given sample. This is a case where `scipy.sparse`\n",
    "matrices can be useful, in that they are much more memory-efficient\n",
    "than NumPy arrays.\n",
    "**End of note**\n",
    "\n",
    "#### A Simple Example: the Iris Dataset\n",
    "\n",
    "##### The application problem\n",
    "\n",
    "As an example of a simple dataset, let us a look at the\n",
    "iris data stored by scikit-learn. Suppose we want to recognize species of\n",
    "irises. The data consists of measurements of\n",
    "three different species of irises:\n",
    "\n",
    "| ![](images/iris_setosa.jpg) | ![](images/iris_versicolor.jpg) | ![](images/iris_virginica.jpg) |\n",
    "| :------------------: | :----------------------: | :---------------------: |\n",
    "| Setosa Iris          | Versicolor Iris          | Virginica Iris          |\n",
    "\n",
    "**Start of admonition: Quick Question:**\n",
    "\n",
    "**If we want to design an algorithm to recognize iris species, what\n",
    "might the data be?**\n",
    "\n",
    "Remember: we need a 2D array of size `[n_samples x n_features]`.\n",
    "\n",
    "- What would the `n_samples` refer to?\n",
    "- What might the `n_features` refer to?\n",
    "**End of admonition**\n",
    "\n",
    "Remember that there must be a **fixed** number of features for each\n",
    "sample, and feature number `i` must be a similar kind of quantity for\n",
    "each sample.\n",
    "\n",
    "##### Loading the Iris Data with Scikit-learn\n",
    "\n",
    "Scikit-learn has a very straightforward set of data on these iris\n",
    "species. The data consist of the following:\n",
    "\n",
    "- Features in the Iris dataset:\n",
    "\n",
    "  * sepal length (cm)\n",
    "  * sepal width (cm)\n",
    "  * petal length (cm)\n",
    "  * petal width (cm)\n",
    "\n",
    "- Target classes to predict:\n",
    "\n",
    "  * Setosa\n",
    "  * Versicolour\n",
    "  * Virginica\n",
    "\n",
    "{mod}`scikit-learn` embeds a copy of the iris CSV file along with a\n",
    "function to load it into NumPy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1405be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec25e574",
   "metadata": {},
   "source": [
    "**Start of note**\n",
    "**Import sklearn** Note that scikit-learn is imported as {mod}`sklearn`\n",
    "**End of note**\n",
    "\n",
    "The features of each sample flower are stored in the `data` attribute\n",
    "of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007203fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabff013",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = iris.data.shape\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f33791",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564a6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a5fc00",
   "metadata": {},
   "source": [
    "The information about the class of each sample is stored in the\n",
    "`target` attribute of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280b84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebca280",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaae1267",
   "metadata": {},
   "source": [
    "The names of the classes are stored in the last attribute, namely\n",
    "`target_names`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d5ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c2fe04",
   "metadata": {},
   "source": [
    "This data is four-dimensional, but we can visualize two of the\n",
    "dimensions at a time using a scatter plot:\n",
    "\n",
    "**Start of note**\n",
    "\n",
    "There is a more elaborate visualization of this dataset is detailed in the\n",
    ":ref:`statistics` chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f421b6",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from matplotlib import ticker\n",
    "\n",
    "# The indices of the features that we are plotting\n",
    "x_index = 0\n",
    "y_index = 1\n",
    "\n",
    "# this formatter will label the colorbar with the correct target names\n",
    "formatter = ticker.FuncFormatter(lambda i, *args: iris.target_names[int(i)])\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.scatter(iris.data[:, x_index], iris.data[:, y_index], c=iris.target)\n",
    "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "plt.xlabel(iris.feature_names[x_index])\n",
    "plt.ylabel(iris.feature_names[y_index])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525e622f",
   "metadata": {},
   "source": [
    "**Start of exercise**\n",
    "\n",
    "Can you choose 2 features to find a plot where it is easier to\n",
    "separate the different classes of irises?\n",
    "\n",
    "**Hint**: click on the figure above to see the code that generates it,\n",
    "and modify this code.\n",
    "\n",
    "**End of exercise**\n",
    "\n",
    "## Basic principles of machine learning with Scikit-learn\n",
    "\n",
    "### Introducing the Scikit-learn estimator object\n",
    "\n",
    "Every algorithm is exposed in Scikit-learn via an \"Estimator\" object. For\n",
    "instance a linear regression is:\n",
    "{class}`sklearn.linear_model.LinearRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ce8c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ada5fb",
   "metadata": {},
   "source": [
    "**Estimator parameters**: All the parameters of an estimator can be set\n",
    "when it is instantiated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabdce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(n_jobs=1)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac618f15",
   "metadata": {},
   "source": [
    "#### Fitting on data\n",
    "\n",
    "Let's create some simple data with {ref}`numpy <numpy>`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([0, 1, 2])\n",
    "y = np.array([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19247136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input data for sklearn is 2D: (samples == 3 x features == 1)\n",
    "X = x[:, np.newaxis]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f35d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35683c78",
   "metadata": {},
   "source": [
    "**Estimated parameters**: When data is fitted with an estimator,\n",
    "parameters are estimated from the data at hand. All the estimated\n",
    "parameters are attributes of the estimator object ending by an\n",
    "underscore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf75bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813867aa",
   "metadata": {},
   "source": [
    "### Supervised Learning: Classification and regression\n",
    "\n",
    "In **Supervised Learning**, we have a dataset consisting of both\n",
    "features and labels. The task is to construct an estimator which is able\n",
    "to predict the label of an object given the set of features. A\n",
    "relatively simple example is predicting the species of iris given a set\n",
    "of measurements of its flower. This is a relatively simple task. Some\n",
    "more complicated examples are:\n",
    "\n",
    "- given a multicolor image of an object through a telescope, determine\n",
    "  whether that object is a star, a quasar, or a galaxy.\n",
    "- given a photograph of a person, identify the person in the photo.\n",
    "- given a list of movies a person has watched and their personal rating\n",
    "  of the movie, recommend a list of movies they would like (So-called\n",
    "  *recommender systems*: a famous example is the [Netflix\n",
    "  Prize](https://en.wikipedia.org/wiki/Netflix_prize)).\n",
    "\n",
    "**Start of note**\n",
    ":class: dropdown\n",
    "\n",
    "What these tasks have in common is that there is one or more unknown\n",
    "quantities associated with the object which needs to be determined from\n",
    "other observed quantities.\n",
    "**End of note**\n",
    "\n",
    "Supervised learning is further broken down into two categories,\n",
    "**classification** and **regression**. In classification, the label is\n",
    "discrete, while in regression, the label is continuous. For example, in\n",
    "astronomy, the task of determining whether an object is a star, a\n",
    "galaxy, or a quasar is a classification problem: the label is from three\n",
    "distinct categories. On the other hand, we might wish to estimate the\n",
    "age of an object based on such observations: this would be a regression\n",
    "problem, because the label (age) is a continuous quantity.\n",
    "\n",
    "**Classification**: K nearest neighbors (kNN) is one of the simplest\n",
    "learning strategies: given a new, unknown observation, look up in your\n",
    "reference database which ones have the closest features and assign the\n",
    "predominant class. Let's try it out on our iris classification problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda11d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, datasets\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X, y)\n",
    "\n",
    "# What kind of iris has 3cm x 5cm sepal and 4cm x 2cm petal?\n",
    "iris.target_names[knn.predict([[3, 5, 4, 2]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af51c11",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Create color maps for 3-class classification problem, as with iris\n",
    "cmap_light = ListedColormap([\"#FFAAAA\", \"#AAFFAA\", \"#AAAAFF\"])\n",
    "cmap_bold = ListedColormap([\"#FF0000\", \"#00FF00\", \"#0000FF\"])\n",
    "\n",
    "X = iris.data[:, :2]  # we only take the first two features. We could\n",
    "# avoid this ugly slicing by using a two-dim dataset\n",
    "y = iris.target\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X, y)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max,\n",
    "100))\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "plt.xlabel(\"sepal length (cm)\")\n",
    "plt.ylabel(\"sepal width (cm)\")\n",
    "plt.axis(\"tight\")\n",
    "plt.title('Sepal space and the prediction of the KNN');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c8c4b8",
   "metadata": {},
   "source": [
    "**Regression**: The simplest possible regression setting is the linear\n",
    "regression one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# x from 0 to 30\n",
    "rng = np.random.default_rng()\n",
    "x = 30 * rng.random((20, 1))\n",
    "\n",
    "# y = a*x + b with noise\n",
    "y = 0.5 * x + 1.0 + rng.normal(size=x.shape)\n",
    "\n",
    "# create a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5109f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict y from the data\n",
    "x_new = np.linspace(0, 30, 100)\n",
    "y_new = model.predict(x_new[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff23e71",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "ax = plt.axes()\n",
    "ax.scatter(x, y)\n",
    "ax.plot(x_new, y_new)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.axis(\"tight\");\n",
    "ax.set_title('A plot of a simple linear regression');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37880ccf",
   "metadata": {},
   "source": [
    "### A recap on Scikit-learn's estimator interface\n",
    "\n",
    "Scikit-learn strives to have a uniform interface across all methods, and\n",
    "we’ll see examples of these below. Given a scikit-learn *estimator*\n",
    "object named `model`, the following methods are available:\n",
    "\n",
    "|   |   |\n",
    "| :- | :- |\n",
    "| **All Estimators** | • ``model.fit()`` : fit training data. For supervised learning applications, this accepts two arguments: the data ``X`` and the labels ``y`` (e.g. ``model.fit(X, y)``). For unsupervised learning applications, this accepts only a single argument, the data ``X`` (e.g. ``model.fit(X)``). |\n",
    "| **Supervised estimators** | • ``model.predict()`` : given a trained model, predict the label of a new set of data. This method accepts one argument, the new data ``X_new`` (e.g. ``model.predict(X_new)``), and returns the learned label for each object in the array.<br> • ``model.predict_proba()`` : For classification problems, some estimators also provide this method, which returns the probability that a new observation has each categorical label. In this case, the label with the highest probability is returned by ``model.predict()``.<br> • ``model.score()`` : for classification or regression problems, most (all?) estimators implement a score method. Scores are between 0 and 1, with a larger score indicating a better fit.|\n",
    "| **Unsupervised estimators** | • ``model.transform()`` : given an unsupervised model, transform new data into the new basis. This also accepts one argument ``X_new``, and returns the new representation of the data based on the unsupervised model.<br> • ``model.fit_transform()`` : some estimators implement this method, which more efficiently performs a fit and a transform on the same input data.|\n",
    "\n",
    "### Regularization: what it is and why it is necessary\n",
    "\n",
    "#### Preferring simpler models\n",
    "\n",
    "**Train errors** Suppose you are using a 1-nearest neighbor estimator.\n",
    "How many errors do you expect on your train set?\n",
    "\n",
    "- Train set error is not a good measurement of prediction performance.\n",
    "  You need to leave out a test set.\n",
    "- In general, we should accept errors on the train set.\n",
    "\n",
    "**An example of regularization** The core idea behind regularization is that\n",
    "we are going to prefer models that are simpler, for a certain definition of\n",
    "''simpler'', even if they lead to more errors on the train set.\n",
    "\n",
    "As an example, let's generate with a 9th order polynomial, with noise:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a64d16",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "rng = np.random.default_rng(27446968)\n",
    "x = 2 * rng.random(100) - 1\n",
    "\n",
    "f = lambda t: 1.2 * t**2 + 0.1 * t**3 - 0.4 * t**5 - 0.5 * t**9\n",
    "y = f(x) + 0.4 * rng.normal(size=100)\n",
    "\n",
    "x_test = np.linspace(-1, 1, 100)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(x, y, s=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f0bbc",
   "metadata": {},
   "source": [
    "And now, let's fit a 4th order and a 9th order polynomial to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56860056",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Fitting 4th and 9th order polynomials\n",
    "#\n",
    "# For this we need to engineer features: the n_th powers of x:\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(x, y, s=4)\n",
    "\n",
    "X = np.array([x**i for i in range(5)]).T\n",
    "X_test = np.array([x_test**i for i in range(5)]).T\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, y)\n",
    "plt.plot(x_test, regr.predict(X_test), label=\"4th order\")\n",
    "\n",
    "X = np.array([x**i for i in range(10)]).T\n",
    "X_test = np.array([x_test**i for i in range(10)]).T\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, y)\n",
    "plt.plot(x_test, regr.predict(X_test), label=\"9th order\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.axis(\"tight\")\n",
    "plt.title(\"Fitting a 4th and a 9th order polynomial\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f47c741",
   "metadata": {},
   "source": [
    "With your naked eye, which model do you prefer, the 4th order one, or the 9th\n",
    "order one?\n",
    "\n",
    "Let's look at the ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0f8b2d",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(x, y, s=4)\n",
    "plt.plot(x_test, f(x_test), label=\"truth\")\n",
    "plt.axis(\"tight\")\n",
    "plt.title(\"Ground truth (9th order polynomial)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf42af23",
   "metadata": {},
   "source": [
    "**Start of note**\n",
    ":class: dropdown\n",
    "\n",
    "Regularization is ubiquitous in machine learning. Most scikit-learn\n",
    "estimators have a parameter to tune the amount of regularization. For\n",
    "instance, with k-NN, it is 'k', the number of nearest neighbors used to\n",
    "make the decision. k=1 amounts to no regularization: 0 error on the\n",
    "training set, whereas large k will push toward smoother decision\n",
    "boundaries in the feature space.\n",
    "**End of note**\n",
    "\n",
    "#### Simple versus complex models for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca09db",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# This is an example plot from the tutorial which accompanies an explanation\n",
    "# of the support vector machine GUI.\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "rng = np.random.default_rng(27446968)\n",
    "\n",
    "# Data that is linearly separable\n",
    "def linear_model(rng, n_samples=30):\n",
    "    \"Generate data according to a linear model\"\n",
    "    data = rng.normal(0, 10, (n_samples, 2))\n",
    "    data[: n_samples // 2] -= 15\n",
    "    data[n_samples // 2 :] += 15\n",
    "\n",
    "    labels = np.ones(n_samples)\n",
    "    labels[: n_samples // 2] = -1\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "X, y = linear_model(rng)\n",
    "clf = svm.SVC(kernel=\"linear\")\n",
    "clf.fit(X, y)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax = axes[0]\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, cmap=\"bone\")\n",
    "ax.scatter(\n",
    "    clf.support_vectors_[:, 0],\n",
    "    clf.support_vectors_[:, 1],\n",
    "    s=80,\n",
    "    edgecolors=\"k\",\n",
    "    facecolors=\"none\",\n",
    ")\n",
    "delta = 1\n",
    "y_min, y_max = -50, 50\n",
    "x_min, x_max = -50, 50\n",
    "x = np.arange(x_min, x_max + delta, delta)\n",
    "y = np.arange(y_min, y_max + delta, delta)\n",
    "X1, X2 = np.meshgrid(x, y)\n",
    "Z = clf.decision_function(np.c_[X1.ravel(), X2.ravel()])\n",
    "Z = Z.reshape(X1.shape)\n",
    "ax.contour(\n",
    "    X1, X2, Z, [-1.0, 0.0, 1.0], colors=\"k\", linestyles=[\"dashed\", \"solid\", \"dashed\"]\n",
    ")\n",
    "ax.set_title(\"A linear separation\")\n",
    "\n",
    "# Data with a non-linear separation\n",
    "\n",
    "def nonlinear_model(rng, n_samples=30):\n",
    "    radius = 40 * rng.random(n_samples)\n",
    "    far_pts = radius > 20\n",
    "    radius[far_pts] *= 1.2\n",
    "    radius[~far_pts] *= 1.1\n",
    "\n",
    "    theta = rng.random(n_samples) * np.pi * 2\n",
    "\n",
    "    data = np.empty((n_samples, 2))\n",
    "    data[:, 0] = radius * np.cos(theta)\n",
    "    data[:, 1] = radius * np.sin(theta)\n",
    "\n",
    "    labels = np.ones(n_samples)\n",
    "    labels[far_pts] = -1\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "rng = np.random.default_rng(27446968)\n",
    "\n",
    "X, y = nonlinear_model(rng)\n",
    "clf = svm.SVC(kernel=\"rbf\", gamma=0.001, coef0=0, degree=3)\n",
    "clf.fit(X, y)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, cmap=\"bone\", zorder=2)\n",
    "ax.scatter(\n",
    "    clf.support_vectors_[:, 0],\n",
    "    clf.support_vectors_[:, 1],\n",
    "    s=80,\n",
    "    edgecolors=\"k\",\n",
    "    facecolors=\"none\",\n",
    ")\n",
    "delta = 1\n",
    "y_min, y_max = -50, 50\n",
    "x_min, x_max = -50, 50\n",
    "x = np.arange(x_min, x_max + delta, delta)\n",
    "y = np.arange(y_min, y_max + delta, delta)\n",
    "X1, X2 = np.meshgrid(x, y)\n",
    "Z = clf.decision_function(np.c_[X1.ravel(), X2.ravel()])\n",
    "Z = Z.reshape(X1.shape)\n",
    "ax.contour(\n",
    "    X1,\n",
    "    X2,\n",
    "    Z,\n",
    "    [-1.0, 0.0, 1.0],\n",
    "    colors=\"k\",\n",
    "    linestyles=[\"dashed\", \"solid\", \"dashed\"],\n",
    "    zorder=1,\n",
    ")\n",
    "ax.set_title(\"A non-linear separation\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bceda9",
   "metadata": {},
   "source": [
    "**Start of note**\n",
    ":class: dropdown\n",
    "\n",
    "For classification models, the decision boundary, that separates the\n",
    "class expresses the complexity of the model. For instance, a linear\n",
    "model, that makes a decision based on a linear combination of\n",
    "features, is more complex than a non-linear one.\n",
    "**End of note**\n",
    "\n",
    "## Supervised Learning: Classification of Handwritten Digits\n",
    "\n",
    "### The nature of the data\n",
    "\n",
    "In this section we'll apply scikit-learn to the classification of\n",
    "handwritten digits. This will go a bit beyond the iris classification we\n",
    "saw before: we'll discuss some of the metrics which can be used in\n",
    "evaluating the effectiveness of a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b01d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39313a52",
   "metadata": {},
   "source": [
    "Let us visualize the data and remind us what we're looking at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8d2026",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))  # figure size in inches\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "for i in range(64):\n",
    "    ax = fig.add_subplot(8, 8, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(digits.images[i], cmap=\"binary\", interpolation=\"nearest\")\n",
    "    # label the image with the target value\n",
    "    ax.text(0, 7, str(digits.target[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2d600f",
   "metadata": {},
   "source": [
    "### Visualizing the Data on its principal components\n",
    "\n",
    "A good first-step for many problems is to visualize the data using a\n",
    "*Dimensionality Reduction* technique. We'll start with the most\n",
    "straightforward one, [Principal Component Analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis).\n",
    "\n",
    "PCA seeks orthogonal linear combinations of the features which show the\n",
    "greatest variance, and as such, can help give you a good idea of the\n",
    "structure of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0066543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "proj = pca.fit_transform(digits.data)\n",
    "plt.scatter(proj[:, 0], proj[:, 1], c=digits.target, cmap='Paired')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5239b4b",
   "metadata": {},
   "source": [
    "**Start of admonition: Question**\n",
    "\n",
    "Given these projections of the data, which numbers do you think a\n",
    "classifier might have trouble distinguishing?\n",
    "**End of admonition**\n",
    "\n",
    "### Gaussian Naive Bayes Classification\n",
    "\n",
    "For most classification problems, it's nice to have a simple, fast\n",
    "method to provide a quick baseline classification. If the simple\n",
    "and fast method is sufficient, then we don't have to waste CPU cycles on\n",
    "more complex models. If not, we can use the results of the simple method\n",
    "to give us clues about our data.\n",
    "\n",
    "One good method to keep in mind is Gaussian Naive Bayes\n",
    "({class}`sklearn.naive_bayes.GaussianNB`).\n",
    "\n",
    ":::{sidebar} Old scikit-learn versions\n",
    "{func}`~sklearn.model_selection.train_test_split` is imported from\n",
    "`sklearn.cross_validation`\n",
    ":::\n",
    "\n",
    "**Start of note**\n",
    ":class: dropdown\n",
    "\n",
    "Gaussian Naive Bayes fits a Gaussian distribution to each training label\n",
    "independently on each feature, and uses this to quickly give a rough\n",
    "classification. It is generally not sufficiently accurate for real-world\n",
    "data, but can perform surprisingly well, for instance on text data.\n",
    "**End of note**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd5da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c9accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   digits.data, digits.target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dceda40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1879f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the model to predict the labels of the test data\n",
    "predicted = clf.predict(X_test)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c50e4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = y_test\n",
    "expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6515d00",
   "metadata": {},
   "source": [
    "As above, we plot the digits with the predicted labels to get an idea of\n",
    "how well the classification is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6b426",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# plot the digits: each image is 8x8 pixels\n",
    "fig = plt.figure(figsize=(6, 6))  # figure size in inches\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "for i in range(64):\n",
    "    ax = fig.add_subplot(8, 8, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(X_test.reshape(-1, 8, 8)[i], cmap=\"binary\", interpolation=\"nearest\")\n",
    "\n",
    "    # label the image with the target value\n",
    "    if predicted[i] == expected[i]:\n",
    "        ax.text(0, 7, str(predicted[i]), color=\"green\")\n",
    "    else:\n",
    "        ax.text(0, 7, str(predicted[i]), color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7045f9b",
   "metadata": {},
   "source": [
    "**Start of admonition: Question**\n",
    "\n",
    "Why did we split the data into training and validation sets?\n",
    "\n",
    "**End of admonition**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3200d26",
   "metadata": {},
   "source": [
    "### Quantitative Measurement of Performance\n",
    "\n",
    "We'd like to measure the performance of our estimator without having to\n",
    "resort to plotting examples. A simple method might be to simply compare\n",
    "the number of matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a30db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of correct matches\n",
    "matches = (predicted == expected)\n",
    "matches.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b87518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The total number of data points\n",
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e129cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ratio of correct predictions\n",
    "matches.sum() / float(len(matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b37c49a",
   "metadata": {},
   "source": [
    "We see that more than 80% of the 450 predictions match the input. But\n",
    "there are other more sophisticated metrics that can be used to judge the\n",
    "performance of a classifier: several are available in the\n",
    "{mod}`sklearn.metrics` submodule.\n",
    "\n",
    "One of the most useful metrics is the `classification_report`, which\n",
    "combines several measures and prints a table with the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f74fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7621616",
   "metadata": {},
   "source": [
    "Another enlightening metric for this sort of multi-label classification\n",
    "is a *confusion matrix*: it helps us visualize which labels are being\n",
    "interchanged in the classification errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d68946",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a41dec3",
   "metadata": {},
   "source": [
    "We see here that in particular, the numbers 1, 2, 3, and 9 are often\n",
    "being labeled 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd8ca9b",
   "metadata": {},
   "source": [
    "## Supervised Learning: Regression of Housing Data\n",
    "\n",
    "Here we'll do a short example of a regression problem: learning a\n",
    "continuous value from a set of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5117a7da",
   "metadata": {},
   "source": [
    "### A quick look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bc5e4e",
   "metadata": {},
   "source": [
    "We'll use the California house prices set, available in Scikit-learn.\n",
    "This records measurements of 8 attributes of housing markets in\n",
    "California, as well as the median price. The question is: can you predict\n",
    "the price of a new market given its attributes?:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3389979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c48c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d75cf56",
   "metadata": {},
   "source": [
    "We can see that there are just over 20000 data points.\n",
    "\n",
    "The `DESCR` variable has a long description of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb4a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea6ab9",
   "metadata": {},
   "source": [
    "It often helps to quickly visualize pieces of the data using histograms,\n",
    "scatter plots, or other plot types. With matplotlib, let us show a\n",
    "histogram of the target values: the median price in each neighborhood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c60a44",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.hist(data.target)\n",
    "plt.xlabel(\"price ($100k)\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f653cf",
   "metadata": {},
   "source": [
    "Let's have a quick look to see if some features are more relevant than\n",
    "others for our problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e36835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(8, 8))\n",
    "axes = axes.ravel()\n",
    "for index, feature_name in enumerate(data.feature_names):\n",
    "    ax = axes[index]\n",
    "    ax.scatter(data.data[feature_name], data.target)\n",
    "    ax.set_ylabel(\"Price\", size=15)\n",
    "    ax.set_xlabel(feature_name, size=15)\n",
    "axes[-1].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c55b78e",
   "metadata": {},
   "source": [
    "This is a manual version of a technique called **feature selection**.\n",
    "\n",
    "**Start of note**\n",
    ":class: dropdown\n",
    "\n",
    "Sometimes, in Machine Learning it is useful to use feature selection to\n",
    "decide which features are the most useful for a particular problem.\n",
    "Automated methods exist which quantify this sort of exercise of choosing\n",
    "the most informative features.\n",
    "**End of note**\n",
    "\n",
    "### Predicting Home Prices: a Simple Linear Regression\n",
    "\n",
    "Now we'll use `scikit-learn` to perform a simple linear regression on\n",
    "the housing data. There are many possibilities of regressors to use. A\n",
    "particularly simple one is `LinearRegression`: this is basically a\n",
    "wrapper around an ordinary least squares calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a1005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target)\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e8fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_test)\n",
    "expected = y_test\n",
    "print(\"RMS: %s\" % np.sqrt(np.mean((predicted - expected) ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9975e7",
   "metadata": {},
   "source": [
    "We can plot the error: expected as a function of predicted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69f34b9",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.scatter(expected, predicted)\n",
    "plt.plot([0, 8], [0, 8], \"--k\")\n",
    "plt.axis(\"tight\")\n",
    "plt.xlabel(\"True price ($100k)\")\n",
    "plt.ylabel(\"Predicted price ($100k)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53095b8",
   "metadata": {},
   "source": [
    "**Start of note**\n",
    ":class: dropdown\n",
    "\n",
    "The prediction at least correlates with the true price, though there are\n",
    "clearly some biases. We could imagine evaluating the performance of the\n",
    "regressor by, say, computing the RMS residuals between the true and\n",
    "predicted price. There are some subtleties in this, however, which we'll\n",
    "cover in a later section.\n",
    "**End of note**\n",
    "\n",
    "**Start of exercise**\n",
    "\n",
    "There are many other types of regressors available in scikit-learn:\n",
    "we'll try a more powerful one here.\n",
    "\n",
    "**Use the GradientBoostingRegressor class to fit the housing data**.\n",
    "\n",
    "**hint** You can copy and paste some of the above code, replacing\n",
    "{class}`~sklearn.linear_model.LinearRegression` with\n",
    "{class}`~sklearn.ensemble.GradientBoostingRegressor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433781d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# Instantiate the model, fit the results, and scatter in vs. out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19aea7e",
   "metadata": {},
   "source": [
    "**End of exercise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c17426",
   "metadata": {},
   "source": [
    "**See the [corresponding page](/packages/scikit-learn/index.html) for solution**\n",
    "\n",
    "## Measuring prediction performance\n",
    "\n",
    "### A quick test on the K-neighbors classifier\n",
    "\n",
    "Here we'll continue to look at the digits data, but we'll switch to the\n",
    "K-Neighbors classifier. The K-neighbors classifier is an instance-based\n",
    "classifier. The K-neighbors classifier predicts the label of\n",
    "an unknown point based on the labels of the *K* nearest points in the\n",
    "parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d141393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data (again)\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6450b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train the classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the results using metrics\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "print(metrics.confusion_matrix(y_pred, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511936a4",
   "metadata": {},
   "source": [
    "Apparently, we've found a perfect classifier! But this is misleading for\n",
    "the reasons we saw before: the classifier essentially \"memorizes\" all the\n",
    "samples it has already seen. To really test how well this algorithm\n",
    "does, we need to try some samples it *hasn't* yet seen.\n",
    "\n",
    "This problem also occurs with regression models. In the following we\n",
    "fit an other instance-based model named \"decision tree\" to the California\n",
    "Housing price dataset we introduced previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cc0cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebb2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_california_housing(as_frame=True)\n",
    "clf = DecisionTreeRegressor().fit(data.data, data.target)\n",
    "predicted = clf.predict(data.data)\n",
    "expected = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e3fed",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.scatter(expected, predicted)\n",
    "plt.plot([0, 5], [0, 5], \"--k\")\n",
    "plt.axis(\"tight\")\n",
    "plt.xlabel(\"True price ($100k)\")\n",
    "plt.ylabel(\"Predicted price ($100k)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf00bd",
   "metadata": {},
   "source": [
    "Here again the predictions are seemingly perfect as the model was able to\n",
    "perfectly memorize the training set.\n",
    "\n",
    "**Start of warning**\n",
    "**Performance on test set**\n",
    "\n",
    "Performance on test set does not measure overfit (as described above)\n",
    "**End of warning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0dfc3b",
   "metadata": {},
   "source": [
    "### A correct approach: Using a validation set\n",
    "\n",
    "Learning the parameters of a prediction function and testing it on the\n",
    "same data is a methodological mistake: a model that would just repeat the\n",
    "labels of the samples that it has just seen would have a perfect score\n",
    "but would fail to predict anything useful on yet-unseen data.\n",
    "\n",
    "To avoid over-fitting, we have to define two different sets:\n",
    "\n",
    "- a training set X_train, y_train which is used for learning the\n",
    "  parameters of a predictive model\n",
    "- a testing set X_test, y_test which is used for evaluating the fitted\n",
    "  predictive model\n",
    "\n",
    "In scikit-learn such a random split can be quickly computed with the\n",
    "{func}`~sklearn.model_selection.train_test_split` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a778de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c19575",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28449ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%r, %r, %r\" % (X.shape, X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c5b5cc",
   "metadata": {},
   "source": [
    "Now we train on the training data, and test on the testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f8cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=1).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc6398",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c210f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a4fe41",
   "metadata": {},
   "source": [
    "The averaged f1-score is often used as a convenient measure of the\n",
    "overall performance of an algorithm. It appears in the bottom row\n",
    "of the classification report; it can also be accessed directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13440e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_test, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cd7bc6",
   "metadata": {},
   "source": [
    "The over-fitting we saw previously can be quantified by computing the\n",
    "f1-score on the training data itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec139426",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(y_train, clf.predict(X_train), average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4fd053",
   "metadata": {},
   "source": [
    "**Start of note**\n",
    "**Regression metrics** In the case of regression models, we\n",
    "need to use different metrics, such as explained variance.\n",
    "**End of note**\n",
    "\n",
    "### Model Selection via Validation\n",
    "\n",
    "**Start of note**\n",
    ":class: dropdown\n",
    "\n",
    "We have applied Gaussian Naives, support vectors machines, and\n",
    "K-nearest neighbors classifiers to the digits dataset. Now that we\n",
    "have these validation tools in place, we can ask quantitatively which\n",
    "of the three estimators works best for this dataset.\n",
    "**End of note**\n",
    "\n",
    "With the default hyper-parameters for each estimator, which gives the best f1\n",
    "score on the **validation set**? Recall that hyperparameters are the\n",
    "parameters set when you instantiate the classifier: for example, the\n",
    "`n_neighbors` in `clf = KNeighborsClassifier(n_neighbors=1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224fe718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e53186",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7521a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Model in [GaussianNB(), KNeighborsClassifier(), LinearSVC(dual=False)]:\n",
    "    clf = Model.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('%s: %s' %\n",
    "          (Model.__class__.__name__, metrics.f1_score(y_test, y_pred, average=\"macro\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f5e393",
   "metadata": {},
   "source": [
    "**Start of exercise**\n",
    "\n",
    "For each classifier, which value for the hyperparameters gives the best\n",
    "results for the digits data? For {class}`~sklearn.svm.LinearSVC`, use\n",
    "`loss='hinge'` and `loss='squared_hinge'`. For\n",
    "{class}`~sklearn.neighbors.KNeighborsClassifier` we use `n_neighbors` between\n",
    "1 and 10. Note that {class}`~sklearn.naive_bayes.GaussianNB` does not have any\n",
    "adjustable hyperparameters.  Your results should look something like this:\n",
    "\n",
    "```text\n",
    "LinearSVC(loss='hinge'): 0.9369152611313591\n",
    "LinearSVC(loss='squared_hinge'): 0.9323387371152745\n",
    "-------------------\n",
    "KNeighbors(n_neighbors=1): 0.9913675218842191\n",
    "KNeighbors(n_neighbors=2): 0.9848442068835102\n",
    "KNeighbors(n_neighbors=3): 0.9867753449543099\n",
    "KNeighbors(n_neighbors=4): 0.9803719053818863\n",
    "KNeighbors(n_neighbors=5): 0.9804562804949924\n",
    "KNeighbors(n_neighbors=6): 0.9757924194139573\n",
    "KNeighbors(n_neighbors=7): 0.9780645792142071\n",
    "KNeighbors(n_neighbors=8): 0.9780645792142071\n",
    "KNeighbors(n_neighbors=9): 0.9780645792142071\n",
    "KNeighbors(n_neighbors=10): 0.9755550897728812\n",
    "```\n",
    "\n",
    "**End of exercise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb7db3d",
   "metadata": {},
   "source": [
    "**See the [corresponding page](/packages/scikit-learn/index.html) for solution**\n",
    "\n",
    "### Cross-validation\n",
    "\n",
    "Cross-validation consists in repeatedly splitting the data in pairs of\n",
    "train and test sets, called 'folds'. Scikit-learn comes with a function\n",
    "to automatically compute score on all these folds. Here we do\n",
    "{class}`~sklearn.model_selection.KFold` with k=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b989cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "cross_val_score(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7707705c",
   "metadata": {},
   "source": [
    "We can use different splitting strategies, such as random splitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b2dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5)\n",
    "cross_val_score(clf, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4da741",
   "metadata": {},
   "source": [
    "**Start of note**\n",
    ":class: dropdown\n",
    "\n",
    "There exist [many different cross-validation\n",
    "strategies](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators)\n",
    "in scikit-learn. They are often useful to take in account non i.i.d datasets.\n",
    "**End of note**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa78356",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization with cross-validation\n",
    "\n",
    "Consider regularized linear models, such as *Ridge Regression*, which uses l2\n",
    "regularization, and *Lasso Regression*, which uses l1 regularization. Choosing\n",
    "their regularization parameter is important.\n",
    "\n",
    "Let us set these parameters on the Diabetes dataset, a simple regression\n",
    "problem. The diabetes data consists of 10 physiological variables (age,\n",
    "sex, weight, blood pressure) measure on 442 patients, and an indication\n",
    "of disease progression after one year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "data = load_diabetes()\n",
    "X, y = data.data, data.target\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5c7e74",
   "metadata": {},
   "source": [
    "With the default hyper-parameters: we compute the cross-validation score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90279f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "for Model in [Ridge, Lasso]:\n",
    "    model = Model()\n",
    "    print(f\"{Model.__name__}: {cross_val_score(model, X, y).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec0366a",
   "metadata": {},
   "source": [
    "#### Basic Hyperparameter Optimization\n",
    "\n",
    "We compute the cross-validation score as a function of alpha, the\n",
    "strength of the regularization for {class}`~sklearn.linear_model.Lasso`\n",
    "and {class}`~sklearn.linear_model.Ridge`. We choose 20 values of alpha\n",
    "between 0.0001 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf49611",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-3, -1, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27a80b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 3))\n",
    "for Model in [Lasso, Ridge]:\n",
    "    scores = [cross_val_score(Model(alpha), X, y, cv=3).mean()\n",
    "              for alpha in alphas]\n",
    "    plt.plot(alphas, scores, label=Model.__name__)\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"cross validation score\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7916f6a8",
   "metadata": {},
   "source": [
    "**Start of admonition: Question**\n",
    "\n",
    "Can we trust our results to be actually useful?\n",
    "**End of admonition**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01285d65",
   "metadata": {},
   "source": [
    "#### Automatically Performing Grid Search\n",
    "\n",
    "{class}`sklearn.grid_search.GridSearchCV` is constructed with an\n",
    "estimator, as well as a dictionary of parameter values to be searched.\n",
    "We can find the optimal parameters this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f38da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "for Model in [Ridge, Lasso]:\n",
    "    gscv = GridSearchCV(Model(), dict(alpha=alphas), cv=3).fit(X, y)\n",
    "    print('%s: %s' % (Model.__name__, gscv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3670679c",
   "metadata": {},
   "source": [
    "#### Built-in Hyperparameter Search\n",
    "\n",
    "For some models within scikit-learn, cross-validation can be performed\n",
    "more efficiently on large datasets. In this case, a cross-validated\n",
    "version of the particular model is included. The cross-validated\n",
    "versions of {class}`~sklearn.linear_model.Ridge` and\n",
    "{class}`~sklearn.linear_model.Lasso` are\n",
    "{class}`~sklearn.linear_model.RidgeCV` and\n",
    "{class}`~sklearn.linear_model.LassoCV`, respectively. Parameter search\n",
    "on these estimators can be performed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e9177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "for Model in [RidgeCV, LassoCV]:\n",
    "    model = Model(alphas=alphas, cv=3).fit(X, y)\n",
    "    print('%s: %s' % (Model.__name__, model.alpha_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51723f0",
   "metadata": {},
   "source": [
    "We see that the results match those returned by GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8537b09a",
   "metadata": {},
   "source": [
    "#### Nested cross-validation\n",
    "\n",
    "How do we measure the performance of these estimators? We have used data\n",
    "to set the hyperparameters, so we need to test on actually new data. We\n",
    "can do this by running {func}`~sklearn.model_selection.cross_val_score`\n",
    "on our CV objects. Here there are 2 cross-validation loops going on, this\n",
    "is called *'nested cross validation'*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8303ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Model in [RidgeCV, LassoCV]:\n",
    "    scores = cross_val_score(Model(alphas=alphas, cv=3), X, y, cv=3)\n",
    "    print(Model.__name__, np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d693e244",
   "metadata": {},
   "source": [
    "**Start of note**\n",
    "Note that these results do not match the best results of our curves\n",
    "above, and {class}`~sklearn.linear_model.LassoCV` seems to\n",
    "under-perform {class}`~sklearn.linear_model.RidgeCV`. The reason is\n",
    "that setting the hyper-parameter is harder for Lasso, thus the\n",
    "estimation error on this hyper-parameter is larger.\n",
    "**End of note**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4d65d0",
   "metadata": {},
   "source": [
    "## Unsupervised Learning: Dimensionality Reduction and Visualization\n",
    "\n",
    "Unsupervised learning is applied on X without y: data without labels. A\n",
    "typical use case is to find hidden structure in the data.\n",
    "\n",
    "### Dimensionality Reduction: PCA\n",
    "\n",
    "Dimensionality reduction derives a set of new artificial features smaller\n",
    "than the original feature set. Here we'll use [Principal Component\n",
    "Analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis), a\n",
    "dimensionality reduction that strives to retain most of the variance of\n",
    "the original data. We'll use {class}`sklearn.decomposition.PCA` on the\n",
    "iris dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1a2a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869fa734",
   "metadata": {},
   "source": [
    "**Start of note**\n",
    ":class: dropdown\n",
    "\n",
    "{class}`~sklearn.decomposition.PCA` computes linear combinations of\n",
    "the original features using a truncated Singular Value Decomposition\n",
    "of the matrix X, to project the data onto a base of the top singular\n",
    "vectors.\n",
    "**End of note**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0fc507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2, whiten=True)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620051b3",
   "metadata": {},
   "source": [
    "Once fitted, {class}`~sklearn.decomposition.PCA` exposes the singular\n",
    "vectors in the `components_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245afc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c50adfd",
   "metadata": {},
   "source": [
    "Other attributes are available as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7224ea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f92495",
   "metadata": {},
   "source": [
    "Let us project the iris dataset along those first two dimensions::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bed3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca.transform(X)\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db3979f",
   "metadata": {},
   "source": [
    "{class}`~sklearn.decomposition.PCA` `normalizes` and `whitens` the data, which\n",
    "means that the data is now centered on both components with unit variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5382a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6423f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca.std(axis=0, ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05817810",
   "metadata": {},
   "source": [
    "Furthermore, the samples components do no longer carry any linear\n",
    "correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04231d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(X_pca.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d1d509",
   "metadata": {},
   "source": [
    "With a number of retained components 2 or 3, PCA is useful to visualize\n",
    "the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7263fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "target_ids = range(len(iris.target_names))\n",
    "for i, c, label in zip(target_ids, 'rgbcmykw', iris.target_names):\n",
    "    plt.scatter(X_pca[y == i, 0], X_pca[y == i, 1],\n",
    "                c=c, label=label)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fc496f",
   "metadata": {},
   "source": [
    "**Start of note**\n",
    ":class: dropdown\n",
    "\n",
    "Note that this projection was determined *without* any information\n",
    "about the labels (represented by the colors): this is the sense in\n",
    "which the learning is **unsupervised**. Nevertheless, we see that the\n",
    "projection gives us insight into the distribution of the different\n",
    "flowers in parameter space: notably, *iris setosa* is much more\n",
    "distinct than the other two species.\n",
    "**End of note**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f24b948",
   "metadata": {},
   "source": [
    "### Visualization with a non-linear embedding: tSNE\n",
    "\n",
    "For visualization, more complex embeddings can be useful (for statistical\n",
    "analysis, they are harder to control). {class}`sklearn.manifold.TSNE` is\n",
    "such a powerful manifold learning method. We apply it to the *digits*\n",
    "dataset, as the digits are vectors of dimension 8\\*8 = 64. Embedding them\n",
    "in 2D enables visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d63a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first 500 data points: it's hard to see 1500 points\n",
    "X = digits.data[:500]\n",
    "y = digits.target[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b01547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform with a TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "X_2d = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba03c216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "target_ids = range(len(digits.target_names))\n",
    "plt.figure(figsize=(6, 5))\n",
    "colors = \"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\", \"orange\", \"purple\"\n",
    "for i, c, label in zip(target_ids, colors, digits.target_names, strict=True):\n",
    "    plt.scatter(X_2d[y == i, 0], X_2d[y == i, 1], c=c, label=label)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aac8ae",
   "metadata": {},
   "source": [
    "**Start of admonition: fit_transform**\n",
    "As {class}`~sklearn.manifold.TSNE` cannot be applied to new data, we\n",
    "need to use its `fit_transform` method.\n",
    "**End of admonition**\n",
    "\n",
    "{class}`sklearn.manifold.TSNE` separates quite well the different classes\n",
    "of digits even though it had no access to the class information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638431af",
   "metadata": {},
   "source": [
    "**Start of exercise**\n",
    "\n",
    "{mod}`sklearn.manifold` has many other non-linear embeddings. Try\n",
    "them out on the digits dataset. Could you judge their quality without\n",
    "knowing the labels `y`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2eb798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e482dc",
   "metadata": {},
   "source": [
    "**End of exercise**\n",
    "\n",
    "## Parameter selection, Validation, and Testing\n",
    "\n",
    "### Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "**Start of admonition: See also**\n",
    "\n",
    "This section is adapted from [Andrew Ng's excellent\n",
    "Coursera course](https://www.coursera.org/course/ml)\n",
    "**End of admonition**\n",
    "\n",
    "The issues associated with validation and cross-validation are some of\n",
    "the most important aspects of the practice of machine learning.\n",
    "Selecting the optimal model for your data is vital, and is a piece of\n",
    "the problem that is not often appreciated by machine learning\n",
    "practitioners.\n",
    "\n",
    "The central question is: **If our estimator is underperforming, how\n",
    "should we move forward?**\n",
    "\n",
    "- Use simpler or more complicated model?\n",
    "- Add more features to each observed data point?\n",
    "- Add more training samples?\n",
    "\n",
    "The answer is often counter-intuitive. In particular, **Sometimes using\n",
    "a more complicated model will give worse results.** Also, **Sometimes\n",
    "adding training data will not improve your results.** The ability to\n",
    "determine what steps will improve your model is what separates the\n",
    "successful machine learning practitioners from the unsuccessful.\n",
    "\n",
    "#### Bias-variance trade-off: illustration on a simple regression problem\n",
    "\n",
    "Let us start with a simple 1D regression problem. This\n",
    "will help us to easily visualize the data and the model, and the results\n",
    "generalize easily to higher-dimensional datasets. We'll explore a simple\n",
    "**linear regression** problem, with {mod}`sklearn.linear_model`.\n",
    "\n",
    "We consider the situation where we have only 2 data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a3c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[0.5, 1].T\n",
    "y = [0.5, 1]\n",
    "X_test = np.c_[0, 2].T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b7fe0",
   "metadata": {},
   "source": [
    "Without noise, as linear regression fits the data perfectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f29255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82397544",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, y)\n",
    "plt.plot(X, y, \"o\")\n",
    "plt.plot(X_test, regr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5684757c",
   "metadata": {},
   "source": [
    "In real life situation, we have noise (e.g. measurement noise) in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0543e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(27446968)\n",
    "for _ in range(6):\n",
    "    noisy_X = X + rng.normal(loc=0, scale=0.1, size=X.shape)\n",
    "    plt.plot(noisy_X, y, \"o\")\n",
    "    regr.fit(noisy_X, y)\n",
    "    plt.plot(X_test, regr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6599fa3",
   "metadata": {},
   "source": [
    "As we can see, our linear model captures and amplifies the noise in the\n",
    "data. It displays a lot of variance.\n",
    "\n",
    "We can use another linear estimator that uses regularization, the\n",
    ":class:`~sklearn.linear_model.Ridge` estimator. This estimator\n",
    "regularizes the coefficients by shrinking them to zero, under the\n",
    "assumption that very high correlations are often spurious. The alpha\n",
    "parameter controls the amount of shrinkage used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a65a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.Ridge(alpha=0.1)\n",
    "for _ in range(6):\n",
    "    noisy_X = X + rng.normal(loc=0, scale=0.1, size=X.shape)\n",
    "    plt.plot(noisy_X, y, \"o\")\n",
    "    regr.fit(noisy_X, y)\n",
    "    plt.plot(X_test, regr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19556394",
   "metadata": {},
   "source": [
    "As we can see, the estimator displays much less variance. However it\n",
    "systematically under-estimates the coefficient. It displays a biased\n",
    "behavior.\n",
    "\n",
    "This is a typical example of **bias/variance trade-off**: non-regularized\n",
    "estimator are not biased, but they can display a lot of variance.\n",
    "Highly-regularized models have little variance, but high bias. This bias\n",
    "is not necessarily a bad thing: what matters is choosing the\n",
    "trade-off between bias and variance that leads to the best prediction\n",
    "performance. For a specific dataset there is a sweet spot corresponding\n",
    "to the highest complexity that the data can support, depending on the\n",
    "amount of noise and of observations available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57436713",
   "metadata": {},
   "source": [
    "### Visualizing the Bias/Variance Tradeoff\n",
    "\n",
    "**Start of note**\n",
    ":class: dropdown\n",
    "\n",
    "Given a particular dataset and a model (e.g. a polynomial), we'd like to\n",
    "understand whether bias (underfit) or variance limits prediction, and how\n",
    "to tune the *hyperparameter* (here `d`, the degree of the polynomial)\n",
    "to give the best fit.\n",
    "**End of note**\n",
    "\n",
    "On a given data, let us fit a simple polynomial regression model with\n",
    "varying degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c378d335",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# A polynomial regression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "n_samples = 8\n",
    "\n",
    "def generating_func(x, rng=None, error=0.5):\n",
    "    rng = np.random.default_rng(rng)\n",
    "    return rng.normal(10 - 1.0 / (x + 0.1), error)\n",
    "\n",
    "rng = np.random.default_rng(27446968)\n",
    "x = 10 ** np.linspace(-2, 0, n_samples)\n",
    "y = generating_func(x, rng=rng)\n",
    "\n",
    "x_test = np.linspace(-0.2, 1.2, 1000)\n",
    "\n",
    "titles = [\"d = 1 (under-fit; high bias)\", \"d = 2\", \"d = 6 (over-fit; high variance)\"]\n",
    "degrees = [1, 2, 6]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(9, 3.5))\n",
    "fig.subplots_adjust(left=0.06, right=0.98, bottom=0.15, top=0.85, wspace=0.05)\n",
    "for i, d in enumerate(degrees):\n",
    "    ax = axes[i]\n",
    "    ax.scatter(x, y, marker=\"x\", c=\"k\", s=50)\n",
    "\n",
    "    model = make_pipeline(PolynomialFeatures(d), LinearRegression())\n",
    "    model.fit(x[:, np.newaxis], y)\n",
    "\n",
    "    ax.plot(x_test, model.predict(x_test[:, np.newaxis]), \"-b\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim(-0.2, 1.2)\n",
    "    ax.set_ylim(0, 12)\n",
    "    ax.set_xlabel(\"house size\")\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"price\")\n",
    "    ax.set_title(titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62d2818",
   "metadata": {},
   "source": [
    "**Start of note**\n",
    ":class: dropdown\n",
    "\n",
    "In the above figure, we see fits for three different values of `d`.\n",
    "For `d = 1`, the data is under-fit. This means that the model is too\n",
    "simplistic: no straight line will ever be a good fit to this data. In\n",
    "this case, we say that the model suffers from high bias. The model\n",
    "itself is biased, and this will be reflected in the fact that the data\n",
    "is poorly fit. At the other extreme, for `d = 6` the data is over-fit.\n",
    "This means that the model has too many free parameters (6 in this case)\n",
    "which can be adjusted to perfectly fit the training data. If we add a\n",
    "new point to this plot, though, chances are it will be very far from the\n",
    "curve representing the degree-6 fit. In this case, we say that the model\n",
    "suffers from high variance. The reason for the term \"high variance\" is\n",
    "that if any of the input points are varied slightly, it could result in\n",
    "a very different model.\n",
    "\n",
    "In the middle, for `d = 2`, we have found a good mid-point. It fits\n",
    "the data fairly well, and does not suffer from the bias and variance\n",
    "problems seen in the figures on either side. What we would like is a way\n",
    "to quantitatively identify bias and variance, and optimize the\n",
    "metaparameters (in this case, the polynomial degree d) in order to\n",
    "determine the best algorithm.\n",
    "**End of note**\n",
    "\n",
    "#### Polynomial regression with scikit-learn\n",
    "\n",
    "A polynomial regression is built by pipelining\n",
    "{class}`~sklearn.preprocessing.PolynomialFeatures`\n",
    "and a {class}`~sklearn.linear_model.LinearRegression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbe5b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ad5dab",
   "metadata": {},
   "source": [
    "#### Validation Curves\n",
    "\n",
    "Let us create a dataset like in the example above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6866d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly sample more data\n",
    "rng = np.random.default_rng(27446968)\n",
    "x = rng.random(size=200)\n",
    "y = generating_func(x, rng=rng, error=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20029f7c",
   "metadata": {},
   "source": [
    "Central to quantify bias and variance of a model is to apply it on *test\n",
    "data*, sampled from the same distribution as the train, but that will\n",
    "capture independent noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd41dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training, validation, and testing sets.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71b3c95",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# show the training and validation sets\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(x_train, y_train, color=\"red\", label=\"Training set\")\n",
    "plt.scatter(x_test, y_test, color=\"blue\", label=\"Test set\")\n",
    "plt.title(\"The data\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232c1357",
   "metadata": {},
   "source": [
    "**Validation curve** A validation curve consists in varying a model parameter\n",
    "that controls its complexity (here the degree of the\n",
    "polynomial) and measures both error of the model on training data, and on\n",
    "test data (*eg* with cross-validation). The model parameter is then\n",
    "adjusted so that the test error is minimized:\n",
    "\n",
    "We use {func}`sklearn.model_selection.validation_curve` to compute train\n",
    "and test error, and plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2324f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3be68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = np.arange(1, 21)\n",
    "model = make_pipeline(PolynomialFeatures(), LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cea372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary the \"degrees\" on the pipeline step \"polynomialfeatures\"\n",
    "train_scores, validation_scores = validation_curve(\n",
    "                model, x[:, np.newaxis], y,\n",
    "                param_name='polynomialfeatures__degree',\n",
    "                param_range=degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd43b3d4",
   "metadata": {},
   "source": [
    "Plot the mean train score and validation score across folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dd26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(degrees, validation_scores.mean(axis=1), lw=2, label=\"cross-validation\")\n",
    "plt.plot(degrees, train_scores.mean(axis=1), lw=2, label=\"training\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"degree of fit\")\n",
    "plt.ylabel(\"explained variance\")\n",
    "plt.title(\"Validation curve\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d530ec2",
   "metadata": {},
   "source": [
    "This figure shows why validation is important. On the left side of the\n",
    "plot, we have very low-degree polynomial, which under-fit the data. This\n",
    "leads to a low explained variance for both the training set and the\n",
    "validation set. On the far right side of the plot, we have a very high\n",
    "degree polynomial, which over-fits the data. This can be seen in the fact\n",
    "that the training explained variance is very high, while on the\n",
    "validation set, it is low. Choosing `d` around 4 or 5 gets us the best\n",
    "trade-off.\n",
    "\n",
    "**Start of note**\n",
    ":class: dropdown\n",
    "\n",
    "The astute reader will realize that something is amiss here: in the\n",
    "above plot, `d` around 7 gives the best results. But in the previous plot,\n",
    "we found that `d = 6` vastly over-fits the data. What’s going on here?\n",
    "The difference is the **number of training points** used. In the\n",
    "previous example, there were only eight training points. In this\n",
    "example, we have 100. As a general rule of thumb, the more training\n",
    "points used, the more complicated model can be used. But how can you\n",
    "determine for a given model whether more training points will be\n",
    "helpful? A useful diagnostic for this are learning curves.\n",
    "**End of note**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952318f3",
   "metadata": {},
   "source": [
    "#### Learning Curves\n",
    "\n",
    "A learning curve shows the training and validation score as a\n",
    "function of the number of training points. Note that when we train on a\n",
    "subset of the training data, the training score is computed using\n",
    "this subset, not the full training set. This curve gives a\n",
    "quantitative view into how beneficial it will be to add training\n",
    "samples.\n",
    "\n",
    "**Start of admonition: Questions:**\n",
    "\n",
    "- As the number of training samples are increased, what do you expect\n",
    "  to see for the training score? For the validation score?\n",
    "- Would you expect the training score to be higher or lower than the\n",
    "  validation score? Would you ever expect this to change?\n",
    "**End of admonition**\n",
    "\n",
    "{mod}`scikit-learn` provides\n",
    "{func}`sklearn.model_selection.learning_curve`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3fcfd4",
   "metadata": {},
   "source": [
    "Here is the pattern for using a learning curve, here with an order 1 polynomial and linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2dd574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(degree=1), LinearRegression())\n",
    "\n",
    "train_sizes, train_scores, validation_scores = learning_curve(\n",
    "    model, x[:, np.newaxis], y, train_sizes=np.logspace(-1, 0, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e0697",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot the mean train score and validation score across folds\n",
    "def plot_model(d):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    model = make_pipeline(PolynomialFeatures(degree=d), LinearRegression())\n",
    "    train_sizes, train_scores, validation_scores = learning_curve(\n",
    "        model, x[:, np.newaxis], y, train_sizes=np.logspace(-1, 0, 20))\n",
    "    plt.plot(train_sizes, validation_scores.mean(axis=1), lw=2, label='cross-validation')\n",
    "    plt.plot(train_sizes, train_scores.mean(axis=1), lw=2, label='training')\n",
    "    plt.ylim(ymin=-0.1, ymax=1)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"number of train samples\")\n",
    "    plt.ylabel(\"explained variance\")\n",
    "    plt.title(f\"Learning curve (degree={d})\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_model(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512936ce",
   "metadata": {},
   "source": [
    "<!--- Check the plot above -->\n",
    "\n",
    "Note that the validation score *generally increases* with a growing\n",
    "training set, while the training score *generally decreases* with a\n",
    "growing training set. As the training size\n",
    "increases, they will converge to a single value.\n",
    "\n",
    "From the above discussion, we know that `d = 1` is a high-bias\n",
    "estimator which under-fits the data. This is indicated by the fact that\n",
    "both the training and validation scores are low. When confronted\n",
    "with this type of learning curve, we can expect that adding more\n",
    "training data will not help: both lines converge to a\n",
    "relatively low score.\n",
    "\n",
    "**When the learning curves have converged to a low score, we have a\n",
    "high bias model.**\n",
    "\n",
    "A high-bias model can be improved by:\n",
    "\n",
    "- Using a more sophisticated model (i.e. in this case, increase `d`)\n",
    "- Gather more features for each sample.\n",
    "- Decrease regularization in a regularized model.\n",
    "\n",
    "Increasing the number of samples, however, does not improve a high-bias\n",
    "model.\n",
    "\n",
    "Now let's look at a high-variance (i.e. over-fit) model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704d4c4b",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plot_model(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd8efa",
   "metadata": {},
   "source": [
    "Here we show the learning curve for `d = 15`. From the above\n",
    "discussion, we know that `d = 15` is a **high-variance** estimator\n",
    "which **over-fits** the data. This is indicated by the fact that the\n",
    "training score is much higher than the validation score. As we add more\n",
    "samples to this training set, the training score will continue to\n",
    "decrease, while the cross-validation error will continue to increase, until they\n",
    "meet in the middle.\n",
    "\n",
    "**Learning curves that have not yet converged with the full training\n",
    "set indicate a high-variance, over-fit model.**\n",
    "\n",
    "A high-variance model can be improved by:\n",
    "\n",
    "- Gathering more training samples.\n",
    "- Using a less-sophisticated model (i.e. in this case, make `d`\n",
    "  smaller)\n",
    "- Increasing regularization.\n",
    "\n",
    "In particular, gathering more features for each sample will not help the\n",
    "results.\n",
    "\n",
    "### Summary on model selection\n",
    "\n",
    "We’ve seen above that an under-performing algorithm can be due to two\n",
    "possible situations: high bias (under-fitting) and high variance\n",
    "(over-fitting). In order to evaluate our algorithm, we set aside a\n",
    "portion of our training data for cross-validation. Using the technique\n",
    "of learning curves, we can train on progressively larger subsets of the\n",
    "data, evaluating the training error and cross-validation error to\n",
    "determine whether our algorithm has high variance or high bias. But what\n",
    "do we do with this information?\n",
    "\n",
    "#### High Bias\n",
    "\n",
    "If a model shows high **bias**, the following actions might help:\n",
    "\n",
    "- **Add more features**. In our example of predicting home prices, it\n",
    "  may be helpful to make use of information such as the neighborhood\n",
    "  the house is in, the year the house was built, the size of the lot,\n",
    "  etc. Adding these features to the training and test sets can improve\n",
    "  a high-bias estimator\n",
    "- **Use a more sophisticated model**. Adding complexity to the model\n",
    "  can help improve on bias. For a polynomial fit, this can be\n",
    "  accomplished by increasing the degree d. Each learning technique has\n",
    "  its own methods of adding complexity.\n",
    "- **Use fewer samples**. Though this will not improve the\n",
    "  classification, a high-bias algorithm can attain nearly the same\n",
    "  error with a smaller training sample. For algorithms which are\n",
    "  computationally expensive, reducing the training sample size can lead\n",
    "  to very large improvements in speed.\n",
    "- **Decrease regularization**. Regularization is a technique used to\n",
    "  impose simplicity in some machine learning models, by adding a\n",
    "  penalty term that depends on the characteristics of the parameters.\n",
    "  If a model has high bias, decreasing the effect of regularization can\n",
    "  lead to better results.\n",
    "\n",
    "#### High Variance\n",
    "\n",
    "If a model shows **high variance**, the following actions might\n",
    "help:\n",
    "\n",
    "- **Use fewer features**. Using a feature selection technique may be\n",
    "  useful, and decrease the over-fitting of the estimator.\n",
    "- **Use a simpler model**. Model complexity and over-fitting go\n",
    "  hand-in-hand.\n",
    "- **Use more training samples**. Adding training samples can reduce the\n",
    "  effect of over-fitting, and lead to improvements in a high variance\n",
    "  estimator.\n",
    "- **Increase Regularization**. Regularization is designed to prevent\n",
    "  over-fitting. In a high-variance model, increasing regularization can\n",
    "  lead to better results.\n",
    "\n",
    "These choices become very important in real-world situations. For\n",
    "example, due to limited telescope time, astronomers must seek a balance\n",
    "between observing a large number of objects, and observing a large\n",
    "number of features for each object. Determining which is more important\n",
    "for a particular learning task can inform the observing strategy that\n",
    "the astronomer employs.\n",
    "\n",
    "### A last word of caution: separate validation and test set\n",
    "\n",
    "Using validation schemes to determine hyper-parameters means that we are\n",
    "fitting the hyper-parameters to the particular validation set. In the\n",
    "same way that parameters can be over-fit to the training set,\n",
    "hyperparameters can be over-fit to the validation set. Because of this,\n",
    "the validation error tends to under-predict the classification error of\n",
    "new data.\n",
    "\n",
    "For this reason, it is recommended to split the data into three sets:\n",
    "\n",
    "- The **training set**, used to train the model (usually ~60% of the\n",
    "  data)\n",
    "- The **validation set**, used to validate the model (usually ~20% of\n",
    "  the data)\n",
    "- The **test set**, used to evaluate the expected error of the\n",
    "  validated model (usually ~20% of the data)\n",
    "\n",
    "Many machine learning practitioners do not separate test set and\n",
    "validation set. But if your goal is to gauge the error of a model on\n",
    "unknown data, using an independent test set is vital.\n",
    "\n",
    "**Start of admonition: See also**\n",
    "\n",
    "**Going further**\n",
    "\n",
    "- The [documentation of scikit-learn](https://scikit-learn.org) is\n",
    "  very complete and didactic.\n",
    "- [Introduction to Machine Learning with Python](https://shop.oreilly.com/product/0636920030515.do),\n",
    "  by Sarah Guido, Andreas Müller\n",
    "  ([notebooks available here](https://github.com/amueller/introduction_to_ml_with_python)).\n",
    "**End of admonition**"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "Python (Pyodide)",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
