---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.17.1
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```{python tags=c("hide-input")}
import numpy as np
# For doctest on headless environments
import matplotlib.pyplot as plt
```

# Numerical operations on arrays

## Elementwise operations

### Basic operations

With scalars:

```{python}
a = np.array([1, 2, 3, 4])
a + 1
```

```{python}
2**a
```

All arithmetic operates elementwise:

```{python}
b = np.ones(4) + 1
a - b
```

```{python}
a * b
```

```{python}
j = np.arange(5)
2**(j + 1) - j
```

These operations are of course much faster than if you did them in pure python:

```{python}
a = np.arange(10000)
%timeit a + 1
```

```{python}
l = range(10000)
%timeit [i+1 for i in l]
```

:::{warning}
**Array multiplication is not matrix multiplication:**

```{python}
c = np.ones((3, 3))
c * c                   # NOT matrix multiplication!
```
:::

:::{note}
**Matrix multiplication:**

```{python}
c @ c
```
:::

:::{admonition} Exercise: Elementwise operations
:class: green

> - Try simple arithmetic elementwise operations: add even elements
>   with odd elements
>
> - Time them against their pure python counterparts using `%timeit`.
>
> - Generate:
>
>   - `[2**0, 2**1, 2**2, 2**3, 2**4]`
>   - `a_j = 2^(3*j) - j`
:::

### Other operations

**Comparisons:**

```{python}
a = np.array([1, 2, 3, 4])
b = np.array([4, 2, 2, 4])
a == b
```

```{python}
a > b
```

:::{tip}
Array-wise comparisons:

```{python}
a = np.array([1, 2, 3, 4])
b = np.array([4, 2, 2, 4])
c = np.array([1, 2, 3, 4])
np.array_equal(a, b)
```

```{python}
np.array_equal(a, c)
```
:::

**Logical operations:**

```{python}
a = np.array([1, 1, 0, 0], dtype=bool)
b = np.array([1, 0, 1, 0], dtype=bool)
np.logical_or(a, b)
```

```{python}
np.logical_and(a, b)
```

**Transcendental functions:**

```{python}
a = np.arange(5)
np.sin(a)
```

```{python}
np.exp(a)
```

```{python}
np.log(np.exp(a))
```

**Shape mismatches**

```{python}
a = np.arange(4)
a + np.array([1, 2])
```

*Broadcasting?* We'll return to that {ref}`later <broadcasting>`.

**Transposition:**

```{python}
a = np.triu(np.ones((3, 3)), 1)   # see help(np.triu)
a
```

```{python}
a.T
```

:::{note}
**The transposition is a view**

The transpose returns a *view* of the original array:

```{python}
a = np.arange(9).reshape(3, 3)
a.T[0, 2] = 999
a.T
```

```{python}
a
```
:::

:::{note}
**Linear algebra**

The sub-module {mod}`numpy.linalg` implements basic linear algebra, such as
solving linear systems, singular value decomposition, etc. However, it is
not guaranteed to be compiled using efficient routines, and thus we
recommend the use of {mod}`scipy.linalg`, as detailed in section
{ref}`scipy_linalg`
:::

:::{admonition} Exercise other operations
:class: green

> - Look at the help for `np.allclose`. When might this be useful?
> - Look at the help for `np.triu` and `np.tril`.
:::

## Basic reductions

### Computing sums

```{python}
x = np.array([1, 2, 3, 4])
np.sum(x)
```

```{python}
x.sum()
```

```{image} images/reductions.png
:align: right
```

Sum by rows and by columns:

```{python}
x = np.array([[1, 1], [2, 2]])
x
```

```{python}
x.sum(axis=0)   # columns (first dimension)
```

```{python}
x[:, 0].sum(), x[:, 1].sum()
```

```{python}
x.sum(axis=1)   # rows (second dimension)
```

```{python}
x[0, :].sum(), x[1, :].sum()
```

:::{tip}
Same idea in higher dimensions:

```{python}
rng = np.random.default_rng(27446968)
x = rng.random((2, 2, 2))
x.sum(axis=2)[0, 1]
```

```{python}
x[0, 1, :].sum()
```
:::

### Other reductions

--- works the same way (and take `axis=`)

**Extrema:**

```{python}
x = np.array([1, 3, 2])
x.min()
```

```{python}
x.max()
```

```{python}
x.argmin()  # index of minimum
```

```{python}
x.argmax()  # index of maximum
```

**Logical operations:**

```{python}
np.all([True, True, False])
```

```{python}
np.any([True, True, False])
```

:::{note}
Can be used for array comparisons:

```{python}
a = np.zeros((100, 100))
np.any(a != 0)
```

```{python}
np.all(a == a)
```

```{python}
a = np.array([1, 2, 3, 2])
b = np.array([2, 2, 3, 2])
c = np.array([6, 4, 4, 5])
((a <= b) & (b <= c)).all()
```
:::

**Statistics:**

```{python}
x = np.array([1, 2, 3, 1])
y = np.array([[1, 2, 3], [5, 6, 1]])
x.mean()
```

```{python}
np.median(x)
```

```{python}
np.median(y, axis=-1) # last axis
```

```{python}
x.std()          # full population standard dev.
```

... and many more (best to learn as you go).

:::{admonition} Exercise: Reductions
:class: green

> - Given there is a `sum`, what other function might you expect to see?
> - What is the difference between `sum` and `cumsum`?
:::

::::{topic} Worked Example: diffusion using a random walk algorithm
```{image} random_walk.png
:align: center
```

:::{tip}
Let us consider a simple 1D random walk process: at each time step a
walker jumps right or left with equal probability.

We are interested in finding the typical distance from the origin of a
random walker after `t` left or right jumps? We are going to
simulate many "walkers" to find this law, and we are going to do so
using array computing tricks: we are going to create a 2D array with
the "stories" (each walker has a story) in one direction, and the
time in the other:
:::

:::{only} latex
```{image} random_walk_schema.png
:align: center
```
:::

:::{only} html
```{image} random_walk_schema.png
:align: center
:width: 100%
```
:::

```{python}
n_stories = 1000 # number of walkers
t_max = 200      # time during which we follow the walker
```

We randomly choose all the steps 1 or -1 of the walk:

```{python}
t = np.arange(t_max)
rng = np.random.default_rng()
steps = 2 * rng.integers(0, 1 + 1, (n_stories, t_max)) - 1 # +1 because the high value is exclusive
np.unique(steps) # Verification: all steps are 1 or -1
```

We build the walks by summing steps along the time:

```{python}
positions = np.cumsum(steps, axis=1) # axis = 1: dimension of time
sq_distance = positions**2
```

We get the mean in the axis of the stories:

```{python}
mean_sq_distance = np.mean(sq_distance, axis=0)
```

Plot the results:

```{python}
plt.figure(figsize=(4, 3))
```

```{python}
plt.plot(t, np.sqrt(mean_sq_distance), 'g.', t, np.sqrt(t), 'y-')
```

```{python}
plt.xlabel(r"$t$")
```

```{python}
plt.ylabel(r"$\sqrt{\langle (\delta x)^2 \rangle}$")
plt.tight_layout() # provide sufficient space for labels
```

```{image} auto_examples/images/sphx_glr_plot_randomwalk_001.png
:align: center
:target: auto_examples/plot_randomwalk.html
:width: 50%
```

We find a well-known result in physics: the RMS distance grows as the
square root of the time!
::::

<!---
arithmetic: sum/prod/mean/std
-->
<!---
extrema: min/max
-->
<!---
logical: all/any
-->
<!---
the axis argument
-->
<!---
EXE: verify if all elements in an array are equal to 1
-->
<!---
EXE: verify if any elements in an array are equal to 1
-->
<!---
EXE: load data with loadtxt from a file, and compute its basic statistics
-->
<!---
CHA: implement mean and std using only sum()
-->
(broadcasting)=

## Broadcasting

- Basic operations on `numpy` arrays (addition, etc.) are elementwise

- This works on arrays of the same size.

  > **Nevertheless**
  >
  > , It's also possible to do operations on arrays of different
  >
  > sizes if 
  >
  > *NumPy*
  >
  >  can transform these arrays so that they all have
  >
  > the same size: this conversion is called 
  >
  > **broadcasting**
  >
  > .

The image below gives an example of broadcasting:

:::{only} latex
```{image} images/numpy_broadcasting.png
:align: center
```
:::

:::{only} html
```{image} images/numpy_broadcasting.png
:align: center
:width: 100%
```
:::

Let's verify:

```{python}
a = np.tile(np.arange(0, 40, 10), (3, 1)).T
a
```

```{python}
b = np.array([0, 1, 2])
a + b
```

We have already used broadcasting without knowing it!:

```{python}
a = np.ones((4, 5))
a[0] = 2  # we assign an array of dimension 0 to an array of dimension 1
a
```

A useful trick:

```{python}
a = np.arange(0, 40, 10)
a.shape
```

```{python}
a = a[:, np.newaxis]  # adds a new axis -> 2D array
a.shape
```

```{python}
a
```

```{python}
a + b
```

:::{tip}
Broadcasting seems a bit magical, but it is actually quite natural to
use it when we want to solve a problem whose output data is an array
with more dimensions than input data.
:::

:::{admonition} Worked Example: Broadcasting
:class: green

Let's construct an array of distances (in miles) between cities of
Route 66: Chicago, Springfield, Saint-Louis, Tulsa, Oklahoma City,
Amarillo, Santa Fe, Albuquerque, Flagstaff and Los Angeles.

```{python}
mileposts = np.array([0, 198, 303, 736, 871, 1175, 1475, 1544,
       1913, 2448])
distance_array = np.abs(mileposts - mileposts[:, np.newaxis])
distance_array
```

```{image} images/route66.png
:align: center
:scale: 60
```
:::

A lot of grid-based or network-based problems can also use
broadcasting. For instance, if we want to compute the distance from
the origin of points on a 5x5 grid, we can do

```{python}
x, y = np.arange(5), np.arange(5)[:, np.newaxis]
distance = np.sqrt(x ** 2 + y ** 2)
distance
```

Or in color:

```{python}
plt.pcolor(distance)
```

```{python}
plt.colorbar()
```

```{image} auto_examples/images/sphx_glr_plot_distances_001.png
:align: center
:target: auto_examples/plot_distances.html
:width: 50%
```

**Remark** : the {func}`numpy.ogrid` function allows to directly create vectors x
and y of the previous example, with two "significant dimensions":

```{python}
x, y = np.ogrid[0:5, 0:5]
x, y
```

```{python}
x.shape, y.shape
distance = np.sqrt(x ** 2 + y ** 2)
```

:::{tip}
So, `np.ogrid` is very useful as soon as we have to handle
computations on a grid. On the other hand, `np.mgrid` directly
provides matrices full of indices for cases where we can't (or don't
want to) benefit from broadcasting:

```{python}
x, y = np.mgrid[0:4, 0:4]
x
```

```{python}
y
```
:::

<!---
rules
-->
<!---
some usage examples: scalars, 1-d matrix products
-->
<!---
newaxis
-->
<!---
EXE: add 1-d array to a scalar
-->
<!---
EXE: add 1-d array to a 2-d array
-->
<!---
EXE: multiply matrix from the right with a diagonal array
-->
<!---
CHA: constructing grids -- meshgrid using only newaxis
-->
:::{admonition} See also

{ref}`broadcasting_advanced`: discussion of broadcasting in
the {ref}`advanced_numpy` chapter.
:::

## Array shape manipulation

### Flattening

```{python}
a = np.array([[1, 2, 3], [4, 5, 6]])
a.ravel()
```

```{python}
a.T
```

```{python}
a.T.ravel()
```

Higher dimensions: last dimensions ravel out "first".

### Reshaping

The inverse operation to flattening:

```{python}
a.shape
```

```{python}
b = a.ravel()
b = b.reshape((2, 3))
b
```

Or,

```{python}
a.reshape((2, -1))    # unspecified (-1) value is inferred
```

:::{warning}
`ndarray.reshape` **may** return a view (cf `help(np.reshape)`)),
or copy
:::

:::{tip}
```{python}
b[0, 0] = 99
a
```

Beware: reshape may also return a copy!:

```{python}
a = np.zeros((3, 2))
b = a.T.reshape(3*2)
b[0] = 9
a
```

To understand this you need to learn more about the memory layout of a NumPy array.
:::

### Adding a dimension

Indexing with the `np.newaxis` object allows us to add an axis to an array
(you have seen this already above in the broadcasting section):

```{python}
z = np.array([1, 2, 3])
z
```

```{python}
z[:, np.newaxis]
```

```{python}
z[np.newaxis, :]
```

### Dimension shuffling

```{python}
a = np.arange(4*3*2).reshape(4, 3, 2)
a.shape
```

```{python}
a[0, 2, 1]
```

```{python}
b = a.transpose(1, 2, 0)
b.shape
```

```{python}
b[2, 1, 0]
```

Also creates a view:

```{python}
b[2, 1, 0] = -1
a[0, 2, 1]
```

### Resizing

Size of an array can be changed with `ndarray.resize`:

```{python}
a = np.arange(4)
a.resize((8,))
a
```

However, it must not be referred to somewhere else:

```{python}
b = a
a.resize((4,))
```

<!---
seealso: ``help(np.tensordot)``
-->
<!---
resizing: how to do it, and *when* is it possible (not always!)
-->
<!---
reshaping (demo using an image?)
-->
<!---
dimension shuffling
-->
<!---
when to use: some pre-made algorithm (e.g. in Fortran) accepts only
1-D data, but you'd like to vectorize it
-->
<!---
EXE: load data incrementally from a file, by appending to a resizing array
-->
<!---
EXE: vectorize a pre-made routine that only accepts 1-D data
-->
<!---
EXE: manipulating matrix direct product spaces back and forth (give an example from physics -- spin index and orbital indices)
-->
<!---
EXE: shuffling dimensions when writing a general vectorized function
-->
<!---
CHA: the mathematical 'vec' operation
-->
:::{admonition} Exercise: Shape manipulations
:class: green

- Look at the docstring for `reshape`, especially the notes section which
  has some more information about copies and views.
- Use `flatten` as an alternative to `ravel`. What is the difference?
  (Hint: check which one returns a view and which a copy)
- Experiment with `transpose` for dimension shuffling.
:::

## Sorting data

Sorting along an axis:

```{python}
a = np.array([[4, 3, 5], [1, 2, 1]])
b = np.sort(a, axis=1)
b
```

:::{note}
Sorts each row separately!
:::

In-place sort:

```{python}
a.sort(axis=1)
a
```

Sorting with fancy indexing:

```{python}
a = np.array([4, 3, 1, 2])
j = np.argsort(a)
j
```

```{python}
a[j]
```

Finding minima and maxima:

```{python}
a = np.array([4, 3, 1, 2])
j_max = np.argmax(a)
j_min = np.argmin(a)
j_max, j_min
```

<!---
XXX: need a frame for summaries

* Arithmetic etc. are elementwise operations
* Basic linear algebra, ``@``
* Reductions: ``sum(axis=1)``, ``std()``, ``all()``, ``any()``
* Broadcasting: ``a = np.arange(4); a[:,np.newaxis] + a[np.newaxis,:]``
* Shape manipulation: ``a.ravel()``, ``a.reshape(2, 2)``
* Fancy indexing: ``a[a > 3]``, ``a[[2, 3]]``
* Sorting data: ``.sort()``, ``np.sort``, ``np.argsort``, ``np.argmax``
-->
:::{admonition} Exercise: Sorting
:class: green

> - Try both in-place and out-of-place sorting.
> - Try creating arrays with different dtypes and sorting them.
> - Use `all` or `array_equal` to check the results.
> - Look at `np.random.shuffle` for a way to create sortable input quicker.
> - Combine `ravel`, `sort` and `reshape`.
> - Look at the `axis` keyword for `sort` and rewrite the previous
>   exercise.
:::

## Summary

**What do you need to know to get started?**

- Know how to create arrays : `array`, `arange`, `ones`,
  `zeros`.

- Know the shape of the array with `array.shape`, then use slicing
  to obtain different views of the array: `array[::2]`,
  etc. Adjust the shape of the array using `reshape` or flatten it
  with `ravel`.

- Obtain a subset of the elements of an array and/or modify their values
  with masks

```{python}
a[a < 0] = 0
```

- Know miscellaneous operations on arrays, such as finding the mean or max
  (`array.max()`, `array.mean()`). No need to retain everything, but
  have the reflex to search in the documentation (online docs,
  `help()`)!!

- For advanced use: master the indexing with arrays of integers, as well as
  broadcasting. Know more NumPy functions to handle various array
  operations.

:::{admonition} Quick read
If you want to do a first quick pass through the Scientific Python Lectures
to learn the ecosystem, you can directly skip to the next chapter:
{ref}`matplotlib`.

The remainder of this chapter is not necessary to follow the rest of
the intro part. But be sure to come back and finish this chapter, as
well as to do some more {ref}`exercises <numpy_exercises>`.
:::